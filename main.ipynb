{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 百度网盘AI大赛——图像处理挑战赛： 通用场景手写文字擦除BaseLine\n",
    "\n",
    "* [赛题链接，点我](https://aistudio.baidu.com/aistudio/competition/detail/347/0/introduction)\n",
    "\n",
    "* 本项目使用基于mask指引的方式，让模型对指定位置进行更精确的内容生成。\n",
    "\n",
    "* 模型使用[EraseNet: End-to-End Text Removal in the Wild](https://ieeexplore.ieee.org/document/9180003)。\n",
    "\n",
    "* 本项目视频讲解见B站一心炼银[手写文字擦除](https://www.bilibili.com/video/BV1Sf4y1o7Yq)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、赛题背景说明\n",
    "\n",
    "随着技术发展，OCR扫描在学习、办公等众多场景中被使用，通过技术和算法，对扫描获得的纸张文档上的手写笔迹还原修复，恢复文件本身的样子，使得人们的使用体验越来越便捷。上一期比赛，我们举办了试卷场景下的手写文字擦除，帮助学生党们擦除试卷上的笔迹。本次比赛，我们诚邀各位选手并拓宽场景：不限于试卷，对通用文件上的手写笔迹进行擦除后还原文件，帮助更多人解决扫描上的问题。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、赛题数据说明及预处理\n",
    "\n",
    "本赛题为img2img的图像处理任务，因此数据集也全部以图像格式给出。这里我挑选数据集中两个具有代表性的图像作为示例。\n",
    "\n",
    "* 如下图1所示为第一类，从左到右依次为手写图片，mask，真实图片。这类图片的特点是\n",
    "\n",
    "1、尺寸小，基本上宽高都在1000像素点以内\n",
    "\n",
    "2、数量多，这类图片数据集一共大概25G左右十分庞大\n",
    "\n",
    "3、手写文字有时会覆盖在文档图片上方，因此不能简单的将文字区域像素设置为固定值就完事\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/2711ea44a3bc48d08456fee5871080cbbd5c0476d3a34ef3ac191fe8038648b4)\n",
    "\n",
    "* 如下图2所示为第二类，从左到右依次为手写图片，mask（自己使用代码进行生成，本次比赛数据集官方没有提供这类图片的mask数据），真实图片。这类图片的特点是\n",
    "\n",
    "1、尺寸巨大，有的宽高可以达到5000像素点，如果想要提高性能分，可以重点关注一下如何对该类图片进行处理\n",
    "\n",
    "2、数量少，但是在A榜中的占比却高达0.4，不像训练数据集中的不到0.02。\n",
    "\n",
    "3、是真实的拍照得到的图片，这类图片是先有手写图片，而后才有的真实图片(与第一类图片不一样，第一类是先有真实图片，而后才有的手写图片)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/2f9a3bfa6f44488e9f91cdce8f21ad958c250aeb6be045d891fefe35adae3f85)\n",
    "\n",
    "\n",
    "**以下代码是用来生成mask的函数(不需要运行，仅作为个人想要提高得分来重新生成mask的一个参考)，本项目已经将一类图片生成的mask和二类图片中的十分之一的数据打包作为数据集挂载。**\n",
    "\n",
    "个人认为：虽然机器学习定理告诉我们，训练数据量越多模型效果越好，越不容易过拟合；但这是有前提的，因为我们无法做到全批量梯度下降，真实的训练过程我们只会一次一个小batch的训练，最早期的batch对模型的梯度影响必然会被后期的batch洗掉一部分，反向传播决定了模型不能进行增量学习。所以，在显存不大的情况下，过大训练数据集对精度的提高是有限的，因此二类图片我只取了十分之一作为基线。另外这样也可以平衡训练中一二类图片的比例，对于单个模型来讲是有益的。\n",
    "\n",
    "本项目将图片随机裁剪到512的大小作为模型的输入，并使用了[SwinT接口](https://aistudio.baidu.com/aistudio/projectdetail/3288357)来抽取全局特征。\n",
    "\n",
    "\n",
    "**总结一下：在数据处理部分，我们一共使用了三种策略， 1、缩减数据集25G-->4.1G 2、生成mask引导模型训练 3、随机裁剪至512x512大小**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 生成mask的函数如下\n",
    "\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# 输入：水印图像路劲，原图路劲，保存的mask的路径\n",
    "def generate_one_mask(image_path, gt_path, save_path):\n",
    "    # 读取图像000000\n",
    "    image = Image.open(image_path)\n",
    "    gt = Image.open(gt_path)\n",
    "\n",
    "    # 转成numpy数组格式\n",
    "    image = 255 - np.array(image)[:, :, :3]\n",
    "    gt = 255 - np.array(gt)[:, :, :3]\n",
    "\n",
    "    # 设置阈值\n",
    "    threshold = 15\n",
    "    # 真实图片与手写图片做差，找出mask的位置\n",
    "    diff_image = np.abs(image.astype(np.float32) - gt.astype(np.float32))  \n",
    "    mean_image = np.max(diff_image, axis=-1)\n",
    "\n",
    "    # 将mask二值化，即0和255。\n",
    "    mask = np.greater(mean_image, threshold).astype(np.uint8) * 255\n",
    "    mask[mask < 2] = 0\n",
    "    mask[mask >= 1] = 255\n",
    "    mask = 255 - mask\n",
    "    mask = np.clip(mask, 0, 255)\n",
    "\n",
    "    # 保存\n",
    "    mask = np.array([mask, mask, mask, mask])\n",
    "    mask = mask.transpose(1, 2, 0)\n",
    "    mask = Image.fromarray(mask[:, :, :3])\n",
    "    mask.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、训练模型并可视化训练过程\n",
    "\n",
    "我们模型用的是[Erasenet](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9180003)，模型结构图如下：\n",
    "<div align=center><img src='https://ai-studio-static-online.cdn.bcebos.com/791b8bc051904654a22ffa069f2a36c6549b9e07b7de42489bc1c5fb74ee7df2'></div>\n",
    "<center>Erasenet主体结构</center>\n",
    "\n",
    "运行以下代码块，进行训练。在基线中，提供了一个来自水印智能消除赛的预训练模型，可以加载此模型提高训练速度。训练过程中可以观察到模型输出图片与真实图片的对比，使用VisualDL可以清晰的看到psnr与loss曲线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 解压数据集文件\n",
    "import os\n",
    "if not os.path.exists('dataset/gts'):\n",
    "    !unzip -oq data/data154420/dehw_train_clear.zip -d ./dataset\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 21:51:16.539263 44202 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W0805 21:51:16.593199 44202 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "(Fatal) Operator elementwise_sub raises an paddle::memory::allocation::BadAlloc exception.\nThe exception content is\n:ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 16.000000MB memory on GPU 0, 23.686279GB memory has been allocated and available memory is only 13.562500MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \nIf the above ways do not solve the out of memory problem, you can try to use CUDA managed memory. The command is `export FLAGS_use_cuda_managed_memory=false`.\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:87)\n. (at /paddle/paddle/fluid/imperative/tracer.cc:307)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/media/backup/competition/main.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090/media/backup/competition/main.ipynb#ch0000006vscode-remote?line=66'>67</a>\u001b[0m ValidData \u001b[39m=\u001b[39m ValidDataSet(file_path\u001b[39m=\u001b[39mvaliddataRoot)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090/media/backup/competition/main.ipynb#ch0000006vscode-remote?line=67'>68</a>\u001b[0m ValidDataLoader \u001b[39m=\u001b[39m DataLoader(ValidData, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, drop_last\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B3090/media/backup/competition/main.ipynb#ch0000006vscode-remote?line=70'>71</a>\u001b[0m netG \u001b[39m=\u001b[39m STRnet2_change()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090/media/backup/competition/main.ipynb#ch0000006vscode-remote?line=73'>74</a>\u001b[0m \u001b[39mif\u001b[39;00m CONFIG[\u001b[39m'\u001b[39m\u001b[39mpretrained\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090/media/backup/competition/main.ipynb#ch0000006vscode-remote?line=74'>75</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloaded \u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/media/backup/competition/models/swin_gan.py:43\u001b[0m, in \u001b[0;36mSTRnet2_change.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1 \u001b[39m=\u001b[39m ConvWithActivation(\u001b[39m3\u001b[39m, \u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     40\u001b[0m                                 padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconva \u001b[39m=\u001b[39m ConvWithActivation(\u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     42\u001b[0m                                 padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvb \u001b[39m=\u001b[39m SwinT(\u001b[39m32\u001b[39;49m, \u001b[39m64\u001b[39;49m, (\u001b[39m256\u001b[39;49m, \u001b[39m256\u001b[39;49m), \u001b[39m2\u001b[39;49m, \u001b[39m8\u001b[39;49m, downsample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     44\u001b[0m \u001b[39m# self.convb = ConvWithActivation(32, 64, kernel_size=4, stride=2, padding=1)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres1 \u001b[39m=\u001b[39m Residual(\u001b[39m64\u001b[39m, \u001b[39m64\u001b[39m)\n",
      "File \u001b[0;32m/media/backup/competition/models/miziha.py:472\u001b[0m, in \u001b[0;36mSwinT.__init__\u001b[0;34m(self, in_channels, out_channels, input_resolution, num_heads, window_size, mlp_ratio, qkv_bias, qk_scale, dropout, attention_dropout, droppath, downsample)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerList()\n\u001b[1;32m    470\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m):\n\u001b[1;32m    471\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 472\u001b[0m         SwinTransformerBlock(\n\u001b[1;32m    473\u001b[0m             dim\u001b[39m=\u001b[39;49min_channels, input_resolution\u001b[39m=\u001b[39;49minput_resolution,\n\u001b[1;32m    474\u001b[0m             num_heads\u001b[39m=\u001b[39;49mnum_heads, window_size\u001b[39m=\u001b[39;49mwindow_size,\n\u001b[1;32m    475\u001b[0m             shift_size\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m \u001b[39mif\u001b[39;49;00m (i \u001b[39m%\u001b[39;49m \u001b[39m2\u001b[39;49m \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m) \u001b[39melse\u001b[39;49;00m window_size \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m2\u001b[39;49m,\n\u001b[1;32m    476\u001b[0m             mlp_ratio\u001b[39m=\u001b[39;49mmlp_ratio,\n\u001b[1;32m    477\u001b[0m             qkv_bias\u001b[39m=\u001b[39;49mqkv_bias, qk_scale\u001b[39m=\u001b[39;49mqk_scale,\n\u001b[1;32m    478\u001b[0m             dropout\u001b[39m=\u001b[39;49mdropout, attention_dropout\u001b[39m=\u001b[39;49mattention_dropout,\n\u001b[1;32m    479\u001b[0m             droppath\u001b[39m=\u001b[39;49mdroppath[i] \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(droppath, \u001b[39mlist\u001b[39;49m) \u001b[39melse\u001b[39;49;00m droppath))\n\u001b[1;32m    481\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcnn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv2D(in_channels\u001b[39m=\u001b[39min_channels,\n\u001b[1;32m    482\u001b[0m                      out_channels\u001b[39m=\u001b[39mout_channels,\n\u001b[1;32m    483\u001b[0m                      kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    484\u001b[0m                      stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    485\u001b[0m                      )\n\u001b[1;32m    487\u001b[0m \u001b[39mif\u001b[39;00m downsample:\n",
      "File \u001b[0;32m/media/backup/competition/models/miziha.py:372\u001b[0m, in \u001b[0;36mSwinTransformerBlock.__init__\u001b[0;34m(self, dim, input_resolution, num_heads, window_size, shift_size, mlp_ratio, qkv_bias, qk_scale, dropout, attention_dropout, droppath)\u001b[0m\n\u001b[1;32m    370\u001b[0m mask_windows \u001b[39m=\u001b[39m windows_partition(img_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size)\n\u001b[1;32m    371\u001b[0m mask_windows \u001b[39m=\u001b[39m mask_windows\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size))\n\u001b[0;32m--> 372\u001b[0m attn_mask \u001b[39m=\u001b[39m mask_windows\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m) \u001b[39m-\u001b[39;49m mask_windows\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    373\u001b[0m attn_mask \u001b[39m=\u001b[39m paddle\u001b[39m.\u001b[39mwhere(attn_mask \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m    374\u001b[0m                          paddle\u001b[39m.\u001b[39mones_like(attn_mask) \u001b[39m*\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m100.0\u001b[39m),  \u001b[39m# 这里，关于mask是否真的必要，这部分使整个代码变得复杂了极多\u001b[39;00m\n\u001b[1;32m    375\u001b[0m                          attn_mask)  \u001b[39m# 有些时候，其实我们也想结合图像边缘之间的关系\u001b[39;00m\n\u001b[1;32m    376\u001b[0m attn_mask \u001b[39m=\u001b[39m paddle\u001b[39m.\u001b[39mwhere(attn_mask \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m,  \u001b[39m# 如果将-100设置为0网络也能work的话，Swin将大大减少代码量\u001b[39;00m\n\u001b[1;32m    377\u001b[0m                          paddle\u001b[39m.\u001b[39mzeros_like(attn_mask),\n\u001b[1;32m    378\u001b[0m                          attn_mask)\n",
      "File \u001b[0;32m/media/data1/miniconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/dygraph/math_op_patch.py:299\u001b[0m, in \u001b[0;36mmonkey_patch_math_varbase.<locals>._binary_creator_.<locals>.__impl__\u001b[0;34m(self, other_var)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     math_op \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(_C_ops, op_type)\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mreturn\u001b[39;00m math_op(\u001b[39mself\u001b[39;49m, other_var, \u001b[39m'\u001b[39;49m\u001b[39maxis\u001b[39;49m\u001b[39m'\u001b[39;49m, axis)\n",
      "\u001b[0;31mSystemError\u001b[0m: (Fatal) Operator elementwise_sub raises an paddle::memory::allocation::BadAlloc exception.\nThe exception content is\n:ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 16.000000MB memory on GPU 0, 23.686279GB memory has been allocated and available memory is only 13.562500MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \nIf the above ways do not solve the out of memory problem, you can try to use CUDA managed memory. The command is `export FLAGS_use_cuda_managed_memory=false`.\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:87)\n. (at /paddle/paddle/fluid/imperative/tracer.cc:307)\n"
     ]
    }
   ],
   "source": [
    "# 可视化\n",
    "from visualdl import LogWriter\n",
    "\n",
    "# paddle包\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle.io import DataLoader\n",
    "from dataset.data_loader import TrainDataSet, ValidDataSet\n",
    "\n",
    "# 自定义的loss函数，包含mask的损失和image的损失\n",
    "from loss.Loss import LossWithGAN_STE, LossWithSwin\n",
    "\n",
    "# 使用SwinT增强的Erasenet\n",
    "from models.swin_gan import STRnet2_change\n",
    "\n",
    "# 其他工具\n",
    "import utils\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# 计算psnr\n",
    "log = LogWriter('log')\n",
    "def psnr(img1, img2):\n",
    "   mse = np.mean((img1/1.0 - img2/1.0) ** 2 )\n",
    "   if mse < 1.0e-10:\n",
    "      return 100\n",
    "   return 10 * math.log10(255.0**2/mse)\n",
    "\n",
    "\n",
    "# 训练配置字典\n",
    "CONFIG = {\n",
    "    'modelsSavePath': 'train_models_swin_erasenet',\n",
    "    'batchSize': 10,  # 模型大，batch_size调小一点防崩，拉满显存但刚好不超，就是炼丹仙人~\n",
    "    'traindataRoot': 'dataset',\n",
    "    'validdataRoot': 'dataset',   # 因为数据集量大，且分布一致，就直接取训练集中数据作为验证了。别问，问就是懒\n",
    "    'pretrained': 'train_models_swin_erasenet/base_model.pdparams',\n",
    "    'num_epochs': 100,\n",
    "    'seed': 9420  # 就是爱你！~\n",
    "}\n",
    "\n",
    "\n",
    "# 设置随机种子\n",
    "random.seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "paddle.seed(CONFIG['seed'])\n",
    "# noinspection PyProtectedMember\n",
    "paddle.framework.random._manual_program_seed(CONFIG['seed'])\n",
    "\n",
    "\n",
    "batchSize = CONFIG['batchSize']\n",
    "if not os.path.exists(CONFIG['modelsSavePath']):\n",
    "    os.makedirs(CONFIG['modelsSavePath'])\n",
    "\n",
    "traindataRoot = CONFIG['traindataRoot']\n",
    "validdataRoot = CONFIG['validdataRoot']\n",
    "\n",
    "# 创建数据集容器\n",
    "TrainData = TrainDataSet(training=True, file_path=traindataRoot)\n",
    "TrainDataLoader = DataLoader(TrainData, batch_size=batchSize, shuffle=True,\n",
    "                             num_workers=0, drop_last=True)\n",
    "ValidData = ValidDataSet(file_path=validdataRoot)\n",
    "ValidDataLoader = DataLoader(ValidData, batch_size=1, shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "\n",
    "netG = STRnet2_change()\n",
    "\n",
    "\n",
    "if CONFIG['pretrained'] is not None:\n",
    "    print('loaded ')\n",
    "    weights = paddle.load(CONFIG['pretrained'])\n",
    "    netG.load_dict(weights)\n",
    "\n",
    "\n",
    "# 开始直接上大火\n",
    "lr = 2e-3\n",
    "G_optimizer = paddle.optimizer.Adam(learning_rate=lr, parameters=netG.parameters())\n",
    "\n",
    "\n",
    "loss_function = LossWithGAN_STE()\n",
    "\n",
    "\n",
    "print('OK!')\n",
    "num_epochs = CONFIG['num_epochs']\n",
    "best_psnr = 0\n",
    "iters = 0\n",
    "\n",
    "\n",
    "for epoch_id in range(1, num_epochs + 1):\n",
    "\n",
    "    netG.train()\n",
    "\n",
    "    if epoch_id % 8 == 0:\n",
    "        # 每8个epoch时重置优化器，学习率变为1/10，抖动式学习法\n",
    "        lr /= 10\n",
    "        G_optimizer = paddle.optimizer.Adam(learning_rate=lr, parameters=netG.parameters())\n",
    "\n",
    "    for k, (imgs, gts, masks) in enumerate(TrainDataLoader):\n",
    "        iters += 1\n",
    "\n",
    "        fake_images, mm = netG(imgs)\n",
    "        G_loss = loss_function(masks, fake_images, mm, gts)\n",
    "        G_loss = G_loss.sum()\n",
    "\n",
    "        #后向传播，更新参数的过程\n",
    "        G_loss.backward()\n",
    "        # 最小化loss,更新参数\n",
    "        G_optimizer.step()\n",
    "        # 清除梯度\n",
    "        G_optimizer.clear_grad()\n",
    "\n",
    "        # 打印训练信息\n",
    "        if iters % 100 == 0:\n",
    "            print('epoch{}, iters{}, loss:{:.5f}, lr:{}'.format(\n",
    "                epoch_id, iters, G_loss.item(), G_optimizer.get_lr()\n",
    "            ))\n",
    "            log.add_scalar(tag=\"train_loss\", step=iters, value=G_loss.item())\n",
    "\n",
    "    # 对模型进行评价并保存\n",
    "    netG.eval()\n",
    "    val_psnr = 0\n",
    "\n",
    "    # noinspection PyAssignmentToLoopOrWithParameter\n",
    "    for index, (imgs, gt) in enumerate(ValidDataLoader):\n",
    "        _, _, h, w = imgs.shape\n",
    "        rh, rw = h, w\n",
    "        step = 512\n",
    "        pad_h = step - h if h < step else 0\n",
    "        pad_w = step - w if w < step else 0\n",
    "        m = nn.Pad2D((0, pad_w, 0, pad_h))\n",
    "        imgs = m(imgs)\n",
    "        _, _, h, w = imgs.shape\n",
    "        res = paddle.zeros_like(imgs)\n",
    "        mm_out = paddle.zeros_like(imgs)\n",
    "        mm_in = paddle.zeros_like(imgs)\n",
    "\n",
    "        for i in range(0, h, step):\n",
    "            for j in range(0, w, step):\n",
    "                if h - i < step:\n",
    "                    i = h - step\n",
    "                if w - j < step:\n",
    "                    j = w - step\n",
    "                clip = imgs[:, :, i:i + step, j:j + step]\n",
    "                clip = clip.cuda()\n",
    "                with paddle.no_grad():\n",
    "                    g_images_clip, mm = netG(clip)\n",
    "                g_images_clip = g_images_clip.cpu()\n",
    "                mm = mm.cpu()\n",
    "                clip = clip.cpu()\n",
    "                mm_in[:, :, i:i + step, j:j + step] = mm\n",
    "                g_image_clip_with_mask = clip * (1 - mm) + g_images_clip * mm\n",
    "                res[:, :, i:i + step, j:j + step] = g_image_clip_with_mask\n",
    "\n",
    "\n",
    "        res = res[:, :, :rh, :rw]\n",
    "        # 改变通道\n",
    "        output = utils.pd_tensor2img(res)\n",
    "        target = utils.pd_tensor2img(gt)\n",
    "        mm_in = utils.pd_tensor2img(mm_in)\n",
    "\n",
    "        psnr_value = psnr(output, target)\n",
    "        print('psnr: ', psnr_value)\n",
    "\n",
    "        if index in [2, 3, 5, 7, 11]:\n",
    "            fig = plt.figure(figsize=(20, 10),dpi=100)\n",
    "            # 图一\n",
    "            ax1 = fig.add_subplot(2, 2, 1)  # 1行 2列 索引为1\n",
    "            ax1.imshow(output)\n",
    "            # 图二\n",
    "            ax2 = fig.add_subplot(2, 2, 2)\n",
    "            ax2.imshow(mm_in)\n",
    "            # 图三\n",
    "            ax3 = fig.add_subplot(2, 2, 3)\n",
    "            ax3.imshow(target)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        del res\n",
    "        del gt\n",
    "        del target\n",
    "        del output\n",
    "\n",
    "        val_psnr += psnr_value\n",
    "    ave_psnr = val_psnr / (index + 1)\n",
    "    print('epoch:{}, psnr:{}'.format(epoch_id, ave_psnr))\n",
    "    log.add_scalar(tag=\"valid_psnr\", step=epoch_id, value=ave_psnr)\n",
    "    paddle.save(netG.state_dict(), CONFIG['modelsSavePath'] +\n",
    "                '/STE_{}_{:.4f}.pdparams'.format(epoch_id, ave_psnr\n",
    "                ))\n",
    "    if ave_psnr > best_psnr:\n",
    "        best_psnr = ave_psnr\n",
    "        paddle.save(netG.state_dict(), CONFIG['modelsSavePath'] + '/STE_best.pdparams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、模型预测\n",
    "\n",
    "在模型预测时，我们将单个图片进行重叠裁剪，裁剪之后为512x512的尺寸，将这个序列依次输入网络进行预测。如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "# 加载Erasenet改\n",
    "from models.swin_gan import STRnet2_change\n",
    "import utils\n",
    "from paddle.vision.transforms import Compose, ToTensor\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# 加载我们训练到的最好的模型\n",
    "netG = STRnet2_change()\n",
    "weights = paddle.load('train_models_swin_erasenet/best_submit_model.pdparams')\n",
    "netG.load_dict(weights)\n",
    "netG.eval()\n",
    "\n",
    "\n",
    "def ImageTransform():\n",
    "    return Compose([ToTensor(), ])\n",
    "\n",
    "\n",
    "ImgTrans = ImageTransform()\n",
    "\n",
    "\n",
    "def process(src_image_dir, save_dir):\n",
    "    image_paths = glob.glob(os.path.join(src_image_dir, \"*.jpg\"))\n",
    "    for image_path in image_paths:\n",
    "\n",
    "        # do something\n",
    "        img = Image.open(image_path)\n",
    "        inputImage = paddle.to_tensor([ImgTrans(img)])\n",
    "\n",
    "        _, _, h, w = inputImage.shape\n",
    "        rh, rw = h, w\n",
    "        step = 512\n",
    "        pad_h = step - h if h < step else 0\n",
    "        pad_w = step - w if w < step else 0\n",
    "        m = nn.Pad2D((0, pad_w, 0, pad_h))\n",
    "        imgs = m(inputImage)\n",
    "        _, _, h, w = imgs.shape\n",
    "        res = paddle.zeros_like(imgs)\n",
    "\n",
    "        for i in range(0, h, step):\n",
    "            for j in range(0, w, step):\n",
    "                if h - i < step:\n",
    "                    i = h - step\n",
    "                if w - j < step:\n",
    "                    j = w - step\n",
    "                clip = imgs[:, :, i:i + step, j:j + step]\n",
    "                clip = clip.cuda()\n",
    "                with paddle.no_grad():\n",
    "                    g_images_clip, mm = netG(clip)\n",
    "                g_images_clip = g_images_clip.cpu()\n",
    "                mm = mm.cpu()\n",
    "                clip = clip.cpu()\n",
    "                g_image_clip_with_mask = g_images_clip * mm + clip * (1 - mm)\n",
    "                res[:, :, i:i + step, j:j + step] = g_image_clip_with_mask\n",
    "                del g_image_clip_with_mask, g_images_clip, mm, clip\n",
    "        res = res[:, :, :rh, :rw]\n",
    "        output = utils.pd_tensor2img(res)\n",
    "\n",
    "        # 保存结果图片\n",
    "        save_path = os.path.join(save_dir, os.path.basename(image_path).replace(\".jpg\", \".png\"))\n",
    "        cv2.imwrite(save_path, output)\n",
    "        del output, res\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    assert len(sys.argv) == 3\n",
    "\n",
    "    src_image_dir = sys.argv[1]\n",
    "    save_dir = sys.argv[2]\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    process(src_image_dir, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、打包提交\n",
    "\n",
    "* 1、在本地新建models文件夹，将本项目中models文件夹下文件全部下载放入。\n",
    "\n",
    "* 2、在本地新建train_models_swin_erasenet文件夹，将本项目中train_models_swin_erasenet文件夹下文件全部下载放入。\n",
    "\n",
    "* 3、下载utils.py文件\n",
    "\n",
    "* 4、下载predict.py文件\n",
    "\n",
    "完成之后打包成submit.zip文件，然后就可以进行提交，得分为0.67分左右，psnr为35.6。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、提分思路(不一定能提分，但可以试)\n",
    "\n",
    "> 1、将一类图片和二类图片各单独使用一个模型，如一类图片我们可以使用手写文字擦除挑战赛那边最好的模型。由于一类图片和二类图片良好的可区分性，给这个增加了可实施的可能性。\n",
    "\n",
    "> 2、使用更多的二类图片数据，使用旋转、缩放等更多形式的增广，改进网络模型\n",
    "\n",
    "> 3、改进mask的生成，例如使用腐蚀和膨胀操作，调整真实图片和手写图片做差的阈值。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('paddle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1cc5ff9a5e031fcc72021197eba7c292562f1c99e0e0e5d3966ce2c307a758a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
